{
    "learning_rate_schedule": "one_cycle",
    "learning_rate_schedule_params": {
        "total_steps": -1,
        "max_lr": 0.1,
        "cycle_momentum": false
    },
    "epochs": 5,
    "batch_size": 4,
    "loss": "finegrain",
    "save_embedding_rate": 5,
    "optimizer": "AdamW",
    "optimizer_params": {
        "lr": 0,
        "betas": [0.9, 0.999],
        "weight_decay": 0.01
    },
    "layer":9
}
