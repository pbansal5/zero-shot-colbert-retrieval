auth_token                       None
cache_dir                        None
dataset_name                     wikitext-103-v1
dataset_path                     wikitext
dataset_split                    test
layer                            16
load_from                        hf
max_length                       1024
model_name                       gpt2
model_parallelism                False
normalization_level              word
num_docs_to_rank                 -1
output_dir                       benchmark/bm25_retrieval_gpt2_medium_colbert_rerank_gpt2_layer_16
ranking_logprob_past_tokens      16
ranking_strategy                 first-rerank
retrieved_file                   logs/bm25_retrieval_gpt2_medium_colbert_rerank
retrieved_max_length             256
stride                           4
